{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01753f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9834715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps -> Data Cleaning -> EDA -> Text Preprocessing -> Model Building -> Evaluation -> Improvement -> Website -> Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a2db4",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70750d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c545b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so here as last three columns are null mostly so we drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9662d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "df.rename(columns = {'v1': 'target','v2':'text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68032bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9:41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb063f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d94c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bdc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212af46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52629dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad60b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36e7c9",
   "metadata": {},
   "source": [
    "## 2. EDA(Exploratery data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bdaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df['target'].value_counts(), labels = ['ham','spam'], autopct = \"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da264fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in above data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a210eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk is natural language tool kit and it is used for deeper analysis\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give me the numbers of characters in one row sentence\n",
    "df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words\n",
    "df['text'].apply(lambda x:nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ef6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a45e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ham messages\n",
    "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spam messages\n",
    "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32305a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0841f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.histplot(df[df['target'] == 0]['num_characters'])\n",
    "sns.histplot(df[df['target'] == 1]['num_characters'], color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ade9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.histplot(df[df['target'] == 0]['num_s'])\n",
    "sns.histplot(df[df['target'] == 1]['num_s'], color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.select_dtypes(include=['number']).corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['number']).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e31918",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ad1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text('Hello How are You')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text1(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after adding word_tokenize to the function the output is \n",
    "transform_text1('Hello How are You')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a27d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d33743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to elemenate special cheracters we use\n",
    "def transform_text3(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada72b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will elemenate % and %% from below\n",
    "transform_text3('Hello How are You 20% %% eg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the solution for above problem is as\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc03e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d81680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to elemenate stopwords we use\n",
    "def transform_text4(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here all the words that are not contributing to the meaning of the sentence are elemenated \n",
    "transform_text4('Hello How are You 20% %% eg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd423d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text4('Did you like my presentation on ML?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to get words in their root words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('dancing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to elemenate stopwords we use\n",
    "def transform_text5(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "            \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text5('I Loved the YT Lectures on Machine Learniong, How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text5('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].apply(transform_text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102db6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f541604",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width = 50,height = 50, min_font_size = 10, background_color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(font_path='/Library/Fonts/df',\n",
    "               width=50, height=50, min_font_size=10, background_color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c3520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
